{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nw6Dx3tFfo_x"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from time import sleep\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key = \"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\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_training_file(file_path):\n",
        "    \"\"\"Upload training file to OpenAI\"\"\"\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        response = client.files.create(\n",
        "            file=file,\n",
        "            purpose=\"fine-tune\"\n",
        "        )\n",
        "        return response.id\n",
        "\n",
        "# Upload both training and validation files\n",
        "training_file_id = upload_training_file(\"training_data.jsonl\")"
      ],
      "metadata": {
        "id": "GWuqaBRdzmfz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_file_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jKQ5qgCNDejb",
        "outputId": "ecbe3351-56ab-4831-f38b-789d2c6abd15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file-YFo8d7NtMzGxNnjxExXNss'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_fine_tuning_job(training_file_id, model=\"gpt-4o-mini-2024-07-18\"):\n",
        "    \"\"\"Create a fine-tuning job\"\"\"\n",
        "    response = client.fine_tuning.jobs.create(\n",
        "        training_file=training_file_id,\n",
        "        model=model\n",
        "    )\n",
        "    return response.id\n",
        "\n",
        "# Start the fine-tuning job\n",
        "job_id = create_fine_tuning_job(training_file_id)"
      ],
      "metadata": {
        "id": "EWRHThVoDgL7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w69Qpz4GD13R",
        "outputId": "1c910345-5ad0-4279-d1c3-4e7e9cd11846"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ftjob-TY9yXvGWkHhSbs0rclbm8Nma'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def monitor_job(job_id):\n",
        "    \"\"\"Monitor fine-tuning job progress\"\"\"\n",
        "    while True:\n",
        "        job = client.fine_tuning.jobs.retrieve(job_id)\n",
        "        print(f\"Status: {job.status}\")\n",
        "\n",
        "        if job.status in [\"succeeded\", \"failed\"]:\n",
        "            return job\n",
        "\n",
        "        # List latest events\n",
        "        events = client.fine_tuning.jobs.list_events(\n",
        "            fine_tuning_job_id=job_id,\n",
        "            limit=5\n",
        "        )\n",
        "        for event in events.data:\n",
        "            print(f\"Event: {event.message}\")\n",
        "\n",
        "        sleep(30)  # Check every 30 seconds\n",
        "\n",
        "# Monitor the job until completion\n",
        "job = monitor_job(job_id)\n",
        "if job.status == \"succeeded\":\n",
        "    fine_tuned_model = job.fine_tuned_model\n",
        "    print(f\"Fine-tuned model ID: {fine_tuned_model}\")\n",
        "else:\n",
        "    print(\"Fine-tuning failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRDl3ZzkD2wN",
        "outputId": "a6c90df4-9493-4677-8a6f-b70062c29566"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status: validating_files\n",
            "Event: Validating training file: file-YFo8d7NtMzGxNnjxExXNss\n",
            "Event: Created fine-tuning job: ftjob-TY9yXvGWkHhSbs0rclbm8Nma\n",
            "Status: validating_files\n",
            "Event: Validating training file: file-YFo8d7NtMzGxNnjxExXNss\n",
            "Event: Created fine-tuning job: ftjob-TY9yXvGWkHhSbs0rclbm8Nma\n",
            "Status: validating_files\n",
            "Event: Validating training file: file-YFo8d7NtMzGxNnjxExXNss\n",
            "Event: Created fine-tuning job: ftjob-TY9yXvGWkHhSbs0rclbm8Nma\n",
            "Status: running\n",
            "Event: Fine-tuning job started\n",
            "Event: Files validated, moving job to queued state\n",
            "Event: Validating training file: file-YFo8d7NtMzGxNnjxExXNss\n",
            "Event: Created fine-tuning job: ftjob-TY9yXvGWkHhSbs0rclbm8Nma\n",
            "Status: running\n",
            "Event: Fine-tuning job started\n",
            "Event: Files validated, moving job to queued state\n",
            "Event: Validating training file: file-YFo8d7NtMzGxNnjxExXNss\n",
            "Event: Created fine-tuning job: ftjob-TY9yXvGWkHhSbs0rclbm8Nma\n",
            "Status: running\n",
            "Event: Fine-tuning job started\n",
            "Event: Files validated, moving job to queued state\n",
            "Event: Validating training file: file-YFo8d7NtMzGxNnjxExXNss\n",
            "Event: Created fine-tuning job: ftjob-TY9yXvGWkHhSbs0rclbm8Nma\n",
            "Status: running\n",
            "Event: Fine-tuning job started\n",
            "Event: Files validated, moving job to queued state\n",
            "Event: Validating training file: file-YFo8d7NtMzGxNnjxExXNss\n",
            "Event: Created fine-tuning job: ftjob-TY9yXvGWkHhSbs0rclbm8Nma\n",
            "Status: running\n",
            "Event: Step 12/84: training loss=1.85\n",
            "Event: Step 11/84: training loss=2.41\n",
            "Event: Step 10/84: training loss=2.83\n",
            "Event: Step 9/84: training loss=2.24\n",
            "Event: Step 8/84: training loss=3.30\n",
            "Status: running\n",
            "Event: Step 40/84: training loss=1.09\n",
            "Event: Step 39/84: training loss=1.02\n",
            "Event: Step 38/84: training loss=1.06\n",
            "Event: Step 37/84: training loss=0.42\n",
            "Event: Step 36/84: training loss=0.64\n",
            "Status: running\n",
            "Event: Step 72/84: training loss=0.27\n",
            "Event: Step 71/84: training loss=0.32\n",
            "Event: Step 70/84: training loss=0.48\n",
            "Event: Step 69/84: training loss=0.39\n",
            "Event: Step 68/84: training loss=0.25\n",
            "Status: running\n",
            "Event: Step 84/84: training loss=0.41\n",
            "Event: Step 83/84: training loss=0.28\n",
            "Event: Step 82/84: training loss=0.54\n",
            "Event: Step 81/84: training loss=0.41\n",
            "Event: Step 80/84: training loss=0.51\n",
            "Status: succeeded\n",
            "Fine-tuned model ID: ft:gpt-4o-mini-2024-07-18:cmp::BEFBTwzx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model_id, test_input):\n",
        "    \"\"\"Test the fine-tuned model\"\"\"\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"I already have insurance.\"\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": test_input}\n",
        "        ]\n",
        "    )\n",
        "    return completion.choices[0].message\n"
      ],
      "metadata": {
        "id": "stz2VeKqD9aN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test input\n",
        "test_report = \"\"\"I’m happy with my current provider\"\"\"\n",
        "\n",
        "# Get prediction\n",
        "result = test_model(fine_tuned_model, test_report)\n",
        "print(f\"Prediction: {result.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RowGgZsEGQ2",
        "outputId": "27a8e230-b475-4779-974d-c48fc436f3cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: I completely understand! Many of my clients felt the same way before switching. Sometimes, they discovered they were overpaying or missing out on better coverage. Doesn’t it make sense to see if you’re getting the best deal?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test input\n",
        "test_report = \"I need to talk to my spouse first\"\n",
        "\n",
        "# Get prediction\n",
        "result = test_model(fine_tuned_model, test_report)\n",
        "print(f\"Prediction: {result.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddAdFyW9EGTb",
        "outputId": "e679b7a2-1bf3-4845-c7be-f483e5aed2f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: I understand! It’s a big decision, and I want you both to feel confident. Many couples choose to go through this together, and I can provide information for you to discuss. Let’s make sure you have all the details to share. It’ll help your conversation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2FLUAuw9GCAd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}